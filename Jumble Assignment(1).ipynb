{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jumble Solver\n",
    "The jumble puzzle is a common newspaper puzzle, it contains a series of anagrams that must be solved (see https://en.wikipedia.org/wiki/Jumble). To solve, one must solve each of the individual jumbles. The circled letters are then used to create an additional anagram to be solved. In especially difficult versions, some of the anagrams in the first set can possess multiple solutions. To get the final answer, it is important to know all possible anagrams of a given series of letters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "Your challenge is to solve the five Jumble puzzles using Spark, where it makes sense to do so. You must use Python. If the final puzzle has multiple possible answers, you are to include an algorithm to determine the most likely one. We have provided a dictionary where the \"most common\" English words are scored (1=most frequent, 9887=least frequent, 0=not scored due to infrequency of use). For each puzzle, produce the \"most likely\" (as you determine it) final anagram produced from solving all the other anagrams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution \n",
    "Before getting stat with code, we have to make sure about our programming environment in which I have executed this code and it's running really well. \n",
    "I have used following environment:\n",
    "\n",
    "1.Ubuntu (18.04.2) installed in Virtualbox (6.0.8){64-bit}\n",
    "\n",
    "2.Java 8\n",
    "\n",
    "3.Used Pyspark in jupyternote book\n",
    "\n",
    "# Approach\n",
    "I have provided with Jumble pictures (Picture 1 to Picture 5) and \"freq_dist.json\". \n",
    "So, as the jumble words we can see in those 5 pictures provided with this assignment, I had to first built a .json out of those 5 pictures and named as \"Puzzles.json\".\n",
    "Now, we put  \"Puzzles.json\" and \"freq_dist.json\" in a same folder, open jupyter notebook and startworking on code execution.  \n",
    "\n",
    "# Result\n",
    "I have attached result screenshots and .txt files(Puzzle numerber 1,Puzzle number 2,Puzzle number 3,Puzzle number 4,Puzzle 5) and  with the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import copy\n",
    "from itertools import permutations, product\n",
    "from operator import itemgetter\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import Row, Column, SparkSession\n",
    "import pyspark.sql.functions as SQF\n",
    "import pyspark.sql.types as SQT\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = SparkConf().setMaster(\"local\").setAppName(\"EXE_MAIN\")\n",
    "#sc = SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder.appName(\"MySparkSQL\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------UTIL FUNCTIONS--------------------------\n",
    "def sortLettersUtil(word):\n",
    "    return ''.join(sorted(word))\n",
    "\n",
    "\n",
    "def getLettersAtIdxs(wrd, idxList):\n",
    "    letters = []\n",
    "    for n in idxList:\n",
    "        letters.append(wrd[n])\n",
    "    return letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------DICTIONARY FUNCTIONS--------------------------\n",
    "def createPyDictionary(dictionarySource):\n",
    "  dictionary = json.load(open(dictionarySource, \"rb\"))\n",
    "  for k, _ in dictionary.items():\n",
    "    if dictionary[k] == 0:\n",
    "      dictionary[k] = 9888\n",
    "    return dictionary\n",
    "\n",
    "def createDictionaryDf(dictionarySource):\n",
    "    wordsDict = json.load(open(dictionarySource, \"rb\"))\n",
    "    # Wordlist is a list of lists each containing the word and its frequency rating\n",
    "    wordsList = []\n",
    "    for word in wordsDict.keys():\n",
    "      wordsList.append([word, wordsDict[word]])\n",
    "\n",
    "    dictionarySchema = SQT.StructType([\n",
    "        SQT.StructField('word', SQT.StringType(), False),\n",
    "        SQT.StructField('freq', SQT.IntegerType(), False)\n",
    "    ])\n",
    "    df = spark.createDataFrame(wordsList, dictionarySchema)\n",
    "    udf = SQF.UserDefinedFunction(sortLettersUtil, SQT.StringType())\n",
    "    df = df.withColumn(\"alpha_sorted\", udf(\"word\"))\n",
    "    df = df.replace(0, 9888, \"freq\")\n",
    "    df = df.withColumn(\"wrd_len\", SQF.length(\"word\"))\n",
    "    return df\n",
    "\n",
    "\n",
    "def findAllMatches(alphaSortedWord, df):\n",
    "    df = df.filter(df.alpha_sorted == alphaSortedWord)\n",
    "    df = df.orderBy(df.freq.asc())\n",
    "    df = df.select(\"word\")\n",
    "    matchesList = df.rdd.flatMap(lambda x: x).collect()\n",
    "    return matchesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Puzzle Solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------PUZZLE FUNCS /PUZZLE SOLVING WITH PYSPARK---------------------------\n",
    "def loadPuzzles(puzzPath):\n",
    "    puzzles = json.load(open(puzzPath, \"rb\"))\n",
    "    return puzzles[\"puzzles\"]\n",
    "\n",
    "\n",
    "def createPuzzles(puzzSource):\n",
    "    puzzlesSchema = SQT.StructType([\n",
    "        SQT.StructField('jumbles', SQT.ArrayType(\n",
    "            SQT.MapType(SQT.StringType(), SQT.ArrayType(SQT.ShortType(), False), False), False)),\n",
    "        SQT.StructField('id', SQT.ShortType(), False),\n",
    "        SQT.StructField('finalWordLengths',\n",
    "                        SQT.ArrayType(SQT.ShortType()), False)\n",
    "    ])\n",
    "    df = spark.createDataFrame(puzzSource, puzzlesSchema)\n",
    "    return df\n",
    "\n",
    "\n",
    "def getSinglePuzzleData(allPuzzlesDf, puzz_id):\n",
    "    singlePuzzle = allPuzzlesDf.filter(allPuzzlesDf.id == puzz_id).rdd.flatMap(lambda x: x).collect()\n",
    "    return singlePuzzle\n",
    "\n",
    "\n",
    "def getAllPuzzleData(allPuzzlesDf):\n",
    "    ids = allPuzzlesDf.select('id')\n",
    "    ids = ids.rdd.flatMap(lambda x: x).collect()\n",
    "    puzzDataList = []\n",
    "    for i in ids:\n",
    "        puzzDataList.append(getSinglePuzzleData(allPuzzlesDf, i))\n",
    "    return puzzDataList\n",
    "\n",
    "def createSinglePuzzDf(puzzleData, dictionary):\n",
    "    jumblesList = puzzleData[0]\n",
    "    table = []\n",
    "    for wrdmap in jumblesList:\n",
    "        for key in wrdmap:\n",
    "            srtd = sortLettersUtil(key)\n",
    "            matches = findAllMatches(srtd, dictionary)\n",
    "        circledLetters = []\n",
    "        for wrd in matches:\n",
    "            circledLetters.append(getLettersAtIdxs(wrd, wrdmap[key]))\n",
    "        tRow = (srtd, key, wrdmap[key], matches, circledLetters)\n",
    "        table.append(tRow)\n",
    "    rdd = sc.parallelize(table)\n",
    "    puzzlesSchema = SQT.StructType([\n",
    "        SQT.StructField('alpha_sorted', SQT.StringType(), False),\n",
    "        SQT.StructField('scrambled', SQT.StringType(), False),\n",
    "        SQT.StructField('idxs_list', SQT.ArrayType(\n",
    "            SQT.ShortType(), False), False),\n",
    "        SQT.StructField('matches_list', SQT.ArrayType(\n",
    "            SQT.StringType(), False), False),\n",
    "        SQT.StructField('letters_lists', SQT.ArrayType(\n",
    "            SQT.ArrayType(SQT.StringType(), False), False), False)\n",
    "    ])\n",
    "    df = spark.createDataFrame(rdd, puzzlesSchema)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def createAllPuzzleDFs(batchDataList, dictionary):\n",
    "    puzzlesDictionary = {}\n",
    "    for p in batchDataList:\n",
    "        puzzlesDictionary[p[1]] = {\"df\": createSinglePuzzDf(p, dictionary), \"lengths\": p[2]}\n",
    "    return puzzlesDictionary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|alpha_sorted|scrambled|idxs_list|matches_list            |letters_lists                    |\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|adgln       |nalgd    |[1, 3, 4]|[gland]                 |[[l, n, d]]                      |\n",
      "|ajmor       |ramoj    |[2, 3]   |[major, joram, jarmo]   |[[j, o], [r, a], [r, m]]         |\n",
      "|abcelm      |camble   |[0, 1, 3]|[becalm]                |[[b, e, a]]                      |\n",
      "|aelrwy      |wraley   |[0, 2, 4]|[lawyer, yawler, warely]|[[l, w, e], [y, w, e], [w, r, l]]|\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "\n",
      "3\n",
      "4\n",
      "4\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|alpha_sorted|scrambled|idxs_list|matches_list            |letters_lists                    |\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|bdeln       |bnedl    |[0, 4]   |[blend]                 |[[b, d]]                         |\n",
      "|adiov       |idova    |[0, 3, 4]|[avoid]                 |[[a, i, d]]                      |\n",
      "|ceehsy      |seheyc   |[1, 5]   |[cheesy, sychee]        |[[h, y], [y, e]]                 |\n",
      "|aacemr      |aracem   |[1, 4, 5]|[camera, mareca, acream]|[[a, r, a], [a, c, a], [c, a, m]]|\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "\n",
      "3\n",
      "4\n",
      "3\n",
      "+------------+---------+---------+----------------+----------------------+\n",
      "|alpha_sorted|scrambled|idxs_list|matches_list    |letters_lists         |\n",
      "+------------+---------+---------+----------------+----------------------+\n",
      "|ahsst       |shast    |[0, 3, 4]|[stash]         |[[s, s, h]]           |\n",
      "|deoor       |doore    |[0, 1, 3]|[rooed, rodeo]  |[[r, o, e], [r, o, e]]|\n",
      "|cdiint      |ditnic   |[0, 1, 2]|[indict]        |[[i, n, d]]           |\n",
      "|aciilt      |catili   |[0, 2, 5]|[italic, clitia]|[[i, a, c], [c, i, a]]|\n",
      "+------------+---------+---------+----------------+----------------------+\n",
      "\n",
      "4\n",
      "8\n",
      "+------------+---------+---------+---------------------+------------------------+\n",
      "|alpha_sorted|scrambled|idxs_list|matches_list         |letters_lists           |\n",
      "+------------+---------+---------+---------------------+------------------------+\n",
      "|dikny       |knidy    |[0, 1]   |[dinky]              |[[d, i]]                |\n",
      "|aegil       |legia    |[0, 2]   |[agile, galei, agiel]|[[a, i], [g, l], [a, i]]|\n",
      "|ceenor      |cronee   |[1, 3]   |[encore]             |[[n, o]]                |\n",
      "|deotuv      |tuvedo   |[0, 5]   |[devout]             |[[d, t]]                |\n",
      "+------------+---------+---------+---------------------+------------------------+\n",
      "\n",
      "8\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|alpha_sorted|scrambled|idxs_list|matches_list            |letters_lists                    |\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "|ginrty      |gyrint   |[0, 1, 3]|[trying, trigyn, tyring]|[[t, r, i], [t, r, g], [t, y, i]]|\n",
      "|deirtv      |drivet   |[2, 5]   |[divert]                |[[v, t]]                         |\n",
      "|aaemns      |snamea   |[0, 5]   |[seaman]                |[[s, n]]                         |\n",
      "|cdeeit      |ceedit   |[1, 3, 5]|[deceit]                |[[e, e, t]]                      |\n",
      "|adhosw      |sowdah   |[0, 3]   |[shadow]                |[[s, d]]                         |\n",
      "|ceehkl      |elchek   |[1, 5]   |[kechel, heckle]        |[[e, l], [e, e]]                 |\n",
      "+------------+---------+---------+------------------------+---------------------------------+\n",
      "\n",
      "6\n",
      "8\n"
     ]
    }
   ],
   "source": [
    " #---------------PUZZLE SOLVING WITH PYTHON--------------------------\n",
    "def loadPuzzles(puzzPath):\n",
    "    puzzles = json.load(open(puzzPath, \"rb\"))\n",
    "    return puzzles[\"puzzles\"]    \n",
    "\n",
    "def createPuzzles(puzzSource):\n",
    "    puzzlesSchema = SQT.StructType([\n",
    "        SQT.StructField('jumbles', SQT.ArrayType(\n",
    "            SQT.MapType(SQT.StringType(), SQT.ArrayType(SQT.ShortType(), False), False), False)),\n",
    "        SQT.StructField('id', SQT.ShortType(), False),\n",
    "        SQT.StructField('finalWordLengths',\n",
    "                        SQT.ArrayType(SQT.ShortType()), False)\n",
    "    ])\n",
    "    df = spark.createDataFrame(puzzSource, puzzlesSchema)\n",
    "    return df\n",
    "\n",
    "\n",
    "def getSinglePuzzleData(allPuzzlesDf, puzz_id):\n",
    "    singlePuzzle = allPuzzlesDf.filter(allPuzzlesDf.id == puzz_id).rdd.flatMap(lambda x: x).collect()\n",
    "    return singlePuzzle\n",
    "\n",
    "\n",
    "def getAllPuzzleData(allPuzzlesDf):\n",
    "    ids = allPuzzlesDf.select('id')\n",
    "    ids = ids.rdd.flatMap(lambda x: x).collect()\n",
    "    puzzDataList = []\n",
    "    for i in ids:\n",
    "        puzzDataList.append(getSinglePuzzleData(allPuzzlesDf, i))\n",
    "    return puzzDataList\n",
    "\n",
    "def createSinglePuzzDf(puzzleData, dictionary):\n",
    "    jumblesList = puzzleData[0]\n",
    "    table = []\n",
    "    for wrdmap in jumblesList:\n",
    "        for key in wrdmap:\n",
    "            srtd = sortLettersUtil(key)\n",
    "            matches = findAllMatches(srtd, dictionary)\n",
    "        circledLetters = []\n",
    "        for wrd in matches:\n",
    "            circledLetters.append(getLettersAtIdxs(wrd, wrdmap[key]))\n",
    "        tRow = (srtd, key, wrdmap[key], matches, circledLetters)\n",
    "        table.append(tRow)\n",
    "    rdd = sc.parallelize(table)\n",
    "    puzzlesSchema = SQT.StructType([\n",
    "        SQT.StructField('alpha_sorted', SQT.StringType(), False),\n",
    "        SQT.StructField('scrambled', SQT.StringType(), False),\n",
    "        SQT.StructField('idxs_list', SQT.ArrayType(\n",
    "            SQT.ShortType(), False), False),\n",
    "        SQT.StructField('matches_list', SQT.ArrayType(\n",
    "            SQT.StringType(), False), False),\n",
    "        SQT.StructField('letters_lists', SQT.ArrayType(\n",
    "            SQT.ArrayType(SQT.StringType(), False), False), False)\n",
    "    ])\n",
    "    df = spark.createDataFrame(rdd, puzzlesSchema)\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def createAllPuzzleDFs(batchDataList, dictionary):\n",
    "    puzzlesDictionary = {}\n",
    "    for p in batchDataList:\n",
    "        puzzlesDictionary[p[1]] = {\"df\": createSinglePuzzDf(p, dictionary), \"lengths\": p[2]}\n",
    "    return puzzlesDictionary\n",
    "\n",
    "\n",
    "    \n",
    "def PermutationsFromList(ll, length, pydictionary):\n",
    "    perms = [''.join(i) for i in permutations(ll, r=length)]\n",
    "    validPerms = set()\n",
    "    for p in perms:\n",
    "        if p in pydictionary:\n",
    "            validPerms.add(p)\n",
    "    sortedValidPerms = sorted(list(validPerms), key=lambda x: pydictionary[x])\n",
    "    return sortedValidPerms\n",
    "\n",
    "\n",
    "def createPermutations(ll, length, pydictionary, combosList=[]):\n",
    "    results = []\n",
    "\n",
    "    if (len(combosList) == 0):\n",
    "      perms = PermutationsFromList(ll, length, pydictionary)\n",
    "      for p in perms:\n",
    "        newLetters = list(ll)\n",
    "        for letter in p:\n",
    "            newLetters.remove(letter)\n",
    "        newPermItem = ([p], newLetters)\n",
    "        results.append(newPermItem)\n",
    "      return results\n",
    "\n",
    "    else:\n",
    "      for wrdList, lettersList in combosList:\n",
    "        perms = perms = PermutationsFromList(lettersList, length, pydictionary)\n",
    "        for p in perms:\n",
    "          newWL = copy.copy(wrdList)\n",
    "          newWL.append(p)\n",
    "          newLetters = list(lettersList)\n",
    "          for letter in p:\n",
    "              newLetters.remove(letter)\n",
    "          newPermItem = (newWL, newLetters)\n",
    "          results.append(newPermItem)\n",
    "      return results\n",
    "\n",
    "\n",
    "def makePhrases(startingLettersList, wrdLensList, pydictionary):\n",
    "  results = []\n",
    "  index = 0\n",
    "  for n in wrdLensList:\n",
    "    print(n)\n",
    "    if index == 0:\n",
    "      result = createPermutations(startingLettersList, n, pydictionary)\n",
    "    else:\n",
    "      result = createPermutations(startingLettersList, n, pydictionary, results[-1])\n",
    "    index += 1\n",
    "    results.append(result)\n",
    "  return results[-1]\n",
    "\n",
    "\n",
    "def phrasesSortedByScore(phrasesList, pydictionary):\n",
    "    results = []\n",
    "\n",
    "    for tup in phrasesList:\n",
    "        score = 0\n",
    "        for wrd in tup[0]:\n",
    "            wrdscore = pydictionary[wrd]\n",
    "            score += wrdscore\n",
    "        results.append((tup[0], score))\n",
    "    sortedResults = sorted(results, key=itemgetter(1))\n",
    "    return sortedResults[:10]\n",
    "\n",
    "\n",
    "def printFile(filename, data):\n",
    "    filenameext = filename+\".txt\"\n",
    "    f = open(filenameext, \"w+\")\n",
    "    f.write(\"The Top (10) solution(s) with score(s) for Puzzle\")\n",
    "    f.write(filename)\n",
    "    f.write(\" are as follows:\\n\")\n",
    "    stringdata= str(data)\n",
    "    f.write(stringdata)\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def solvePuzzleBatchAndExport(puzzleDfDataObject, pydictionary):\n",
    "    results = []\n",
    "    for k, v in puzzleDfDataObject.items():\n",
    "        df = v[\"df\"]\n",
    "        lengths = v[\"lengths\"]\n",
    "        df.show(10, False)\n",
    "\n",
    "        mostLikeyLettersList = df.select('letters_lists').rdd.map(\n",
    "            lambda lettersList: lettersList[0][0]).collect()\n",
    "        ll = [item for sublist in mostLikeyLettersList for item in sublist]\n",
    "\n",
    "        allPhrases = makePhrases(ll, lengths, pydictionary)\n",
    "        sortedPhrases = phrasesSortedByScore(allPhrases, pydictionary)\n",
    "        puzzlename = \"Puzzle_\" + str(k)\n",
    "        results.append((puzzlename, sortedPhrases))\n",
    "\n",
    "    for r in results:\n",
    "        printFile(r[0], r[1])\n",
    "    return results\n",
    "\n",
    "\n",
    "# filepath strings\n",
    "PUZZLE_SOURCE= \"puzzles.json\"\n",
    "DICTIONARY_SOURCE= \"freq_dict.json\"\n",
    "\n",
    "# creating dictionaries\n",
    "PY_DICTIONARY = createPyDictionary(DICTIONARY_SOURCE)\n",
    "DF_DICTIONARY = createDictionaryDf(DICTIONARY_SOURCE)\n",
    "\n",
    "# creating puzzles\n",
    "LOAD_PUZZLES = loadPuzzles(PUZZLE_SOURCE)\n",
    "CREATE_PUZZLES = createPuzzles(LOAD_PUZZLES)\n",
    "ALL_PUZZ_DATA_LIST = getAllPuzzleData(CREATE_PUZZLES)\n",
    "CREATE_ALL_PUZZ_DFs = createAllPuzzleDFs(ALL_PUZZ_DATA_LIST, DF_DICTIONARY)\n",
    "\n",
    "# solving puzzles\n",
    "RESULTS = solvePuzzleBatchAndExport(CREATE_ALL_PUZZ_DFs, PY_DICTIONARY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
